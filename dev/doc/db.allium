-- db.allium
--
-- The processing model of a single database within an XTDB node:
-- transaction submission → source log processing → replica log processing → query.
-- Compaction is specified separately: see compaction.allium.
--
-- Two log processors per database:
--   SourceLogProcessor: consumes source log, resolves txs, writes OutputTx to replica log.
--   ReplicaLogProcessor: consumes replica log, applies pre-resolved txs, serves queries.
--
-- Scope: one database (e.g. "xtdb" or a secondary).
-- External: the multi-database orchestration layer (attach/detach).

use "./trie-cat.allium" as trie_cat

------------------------------------------------------------
-- External Entities
------------------------------------------------------------

-- Truly external: managed by the multi-database layer or the environment.

external entity Client {
    -- The party submitting transactions.
}

external entity Log {
    -- An ordered, append-only message stream.
    -- Two instances per database: source_log and replica_log.
    -- See: api/log/Log.kt
}

external entity ObjectStore {
    -- Durable key-value storage for blocks, tries, table-blocks.
}

------------------------------------------------------------
-- Entities
------------------------------------------------------------

-- Behaviourally-relevant fields only; see linked sources for full definitions.

entity LiveIndex {
    -- See: indexer/LiveIndex.kt
    latest_completed_tx: TransactionKey?
    is_full: Boolean

    -- Derived
    has_data: latest_completed_tx != null
}

entity Database {
    -- See: indexer/Indexer.kt
    mode: read_write | read_only
    source_log: Log
    replica_log: Log
}

entity BlockCatalog {
    -- See: catalog/BlockCatalog.kt
    -- Single point of truth for the latest persisted block.
    latest_block: Block?

    -- Derived
    current_block_index: latest_block?.block_index
}

entity TableCatalog {
    -- See: catalog/TableCatalog.kt, table_catalog.clj
    -- Cumulative table metadata: row counts, column types, cardinality sketches.
    -- Accumulated across all blocks; used by the query planner.
    table_metadata: Map<trie_cat/TableRef, TableMetadata>
}

entity SourceLogProcessor {
    -- Consumes source log, resolves transactions, writes OutputTx to replica log.
    -- Has its own LiveIndex, BlockCatalog, TableCatalog, TrieCatalog.
    -- See: indexer/LogProcessor.kt (will be split)
    latest_processed_msg_id: MessageId
    last_flush_check: Instant

    live_index: LiveIndex
    block_catalog: BlockCatalog
    table_catalog: TableCatalog
}

entity ReplicaLogProcessor {
    -- Consumes replica log, applies pre-resolved OutputTx messages.
    -- Has its own LiveIndex, BlockCatalog, TableCatalog, TrieCatalog.
    -- Queries are served from this processor's live index.
    -- See: indexer/LogProcessor.kt (will be split)
    latest_processed_msg_id: MessageId

    live_index: LiveIndex
    block_catalog: BlockCatalog
    table_catalog: TableCatalog
}

-- Storage.VERSION is a compile-time constant; storage_epoch is per-BufferPool.
-- The ReplicaLogProcessor checks incoming TriesAdded messages against these values
-- to discard stale notifications from a previous epoch.
external value current_storage_version: Int   -- See: storage/Storage.kt (VERSION)
external value current_storage_epoch: Int     -- See: buffer_pool/BufferPool.kt (epoch)

------------------------------------------------------------
-- Values
------------------------------------------------------------

value MessageId {
    -- Epoch + offset packed into a long.
    -- See: util/MsgIdUtil.kt
    epoch: Int
    offset: Int
}

value TransactionKey {
    -- See: block/proto/block.proto (TxKey)
    tx_id: Long
    system_time: Instant
}

value Block {
    -- A persisted block in the object store.
    -- See: catalog/BlockCatalog.kt (BlockCatalog.buildBlock)
    block_index: Long
    latest_completed_tx: TransactionKey
    latest_processed_msg_id: MessageId
    replica_log_offset: MessageId   -- replica-log offset of the BlockBoundary that concluded this block
}

value Snapshot {
    -- A point-in-time read view of the database.
    as_of: TransactionKey
}

value TableMetadata {
    -- Per-table cumulative metadata, merged across blocks.
    -- See: table_catalog.clj
    row_count: Long?
}

------------------------------------------------------------
-- Source Log Messages
------------------------------------------------------------

-- Messages on the source log: client-submitted transactions and control messages.
-- See: log/proto/log.proto

entity SourceMessage {
    msg_id: MessageId
    log_timestamp: Instant
    kind: TxMessage | FlushBlockMessage | AttachDbMessage | DetachDbMessage
}

variant TxMessage : SourceMessage {
    -- Client-submitted transaction operations.
    -- See: tx/TxWriter.kt, api/log/Log.kt (Log$Message$Tx) — serialised via TxWriter, not proto.
    system_time: Instant?
    default_tz: String?
    user: String?
}

variant FlushBlockMessage : SourceMessage {
    -- Request to finish the current block.
    -- See: log/proto/log.proto (FlushBlock)
    expected_block_idx: Long?
}

variant AttachDbMessage : SourceMessage {
    -- See: log/proto/log.proto (AttachDatabase)
    db_name: String
}

variant DetachDbMessage : SourceMessage {
    -- See: log/proto/log.proto (DetachDatabase)
    db_name: String
}

------------------------------------------------------------
-- Replica Log Messages
------------------------------------------------------------

-- Messages on the replica log: resolved transactions, block lifecycle, trie notifications.

entity ReplicaMessage {
    msg_id: MessageId
    log_timestamp: Instant
    kind: OutputTxMessage | BlockBoundaryMessage | TriesAddedMessage | BlockUploadedMessage
}

variant OutputTxMessage : ReplicaMessage {
    -- A resolved transaction: the source has executed the tx against its live index
    -- and serialised the per-table results.
    -- Replicas import these directly into their live indexes.
    source_msg_id: MessageId                            -- offset of the original TxMessage on the source log
    tx_key: TransactionKey
    committed: Boolean
    error: Bytes?                                       -- transit-msgpack encoded error, if aborted
    user_metadata: Bytes?                               -- transit-msgpack encoded user metadata
    table_relations: Map<trie_cat/TableRef, Bytes>      -- per-table Arrow IPC payloads (log-data schema)
}

variant BlockBoundaryMessage : ReplicaMessage {
    -- Marks where the source decides to cut the block, before any block I/O.
    -- Serves as the replay anchor for source recovery.
    block_index: Long
    latest_source_msg_id: MessageId     -- source-log offset at the cut point
}

variant TriesAddedMessage : ReplicaMessage {
    -- Notification that new tries exist (from block flush or compaction).
    -- See: log/proto/log.proto (TriesAdded)
    storage_version: Int
    storage_epoch: Int
    tries: List<trie_cat/TrieDetails>
}

variant BlockUploadedMessage : ReplicaMessage {
    -- Notification that a block has been written to the object store.
    -- Sent by the source after finishBlock(); consumed by replicas to refresh catalogs.
    -- See: log/proto/log.proto (BlockUploaded)
    block_index: Long
    latest_processed_msg_id: MessageId
    storage_epoch: Int
}

------------------------------------------------------------
-- Config
------------------------------------------------------------

config {
    flush_timeout: Duration = 4.hours
    max_block_rows: Integer = 102400
}

------------------------------------------------------------
-- Rules: Transaction Submission
------------------------------------------------------------

rule ClientSubmitsTransaction {
    when: ClientSubmitsTx(client, database, tx_ops, opts)

    requires: database.mode == read_write

    ensures:
        let msg = TxMessage.created(
            system_time: opts.system_time,
            default_tz: opts.default_tz,
            user: opts.user
        )
        msg appended to database.source_log
}

------------------------------------------------------------
-- Rules: Source Log Processing
------------------------------------------------------------

-- The SourceLogProcessor subscribes to the source log (consumer group)
-- and processes messages sequentially.
-- For each transaction, it resolves against its own live index,
-- then writes the result as an OutputTxMessage to the replica log.

rule SourceProcessesTx {
    when: msg: TxMessage appended to database.source_log

    requires: msg.msg_id > source.latest_processed_msg_id

    ensures:
        -- Resolve the transaction against the source's live index.
        let result = ResolveTransaction(msg, source.live_index)

        -- Write the resolved result to the replica log.
        let output = OutputTxMessage.created(
            source_msg_id: msg.msg_id,
            tx_key: result.tx_key,
            committed: result.committed,
            error: result.error,
            user_metadata: result.user_metadata,
            table_relations: result.table_relations
        )
        output appended to database.replica_log

        source.latest_processed_msg_id = msg.msg_id

        if source.live_index.is_full:
            SourceBlockFlushNeeded(msg.log_timestamp)
}

rule SourceProcessesFlushBlock {
    when: msg: FlushBlockMessage appended to database.source_log

    requires: msg.msg_id > source.latest_processed_msg_id
    requires: msg.expected_block_idx == source.block_catalog.current_block_index

    ensures:
        source.latest_processed_msg_id = msg.msg_id
        SourceBlockFlushNeeded(msg.log_timestamp)
}

rule SourceProcessesAttachDb {
    when: msg: AttachDbMessage appended to database.source_log

    requires: msg.msg_id > source.latest_processed_msg_id

    ensures:
        source.latest_processed_msg_id = msg.msg_id
        -- Attach handling delegated to multi-database layer.
}

rule SourceProcessesDetachDb {
    when: msg: DetachDbMessage appended to database.source_log

    requires: msg.msg_id > source.latest_processed_msg_id

    ensures:
        source.latest_processed_msg_id = msg.msg_id
        -- Detach handling delegated to multi-database layer.
}

------------------------------------------------------------
-- Rules: Source Block Flushing
------------------------------------------------------------

-- When the source's live index is full or a FlushBlock is received,
-- the source writes a BlockBoundary, flushes to object store,
-- and writes TriesAdded + BlockUploaded to the replica log.

rule SourceFinishesBlock {
    -- log_timestamp is from the message that triggered the flush.
    -- Becomes the as_of for trie registration; the 24-hour garbage_lifetime
    -- grace period absorbs any practical difference between trigger sources.
    when: SourceBlockFlushNeeded(log_timestamp)

    let block_index = (source.block_catalog.current_block_index ?? -1) + 1

    ensures:
        -- 1. Mark the cut point on the replica log.
        let boundary = BlockBoundaryMessage.created(
            block_index: block_index,
            latest_source_msg_id: source.latest_processed_msg_id
        )
        boundary appended to database.replica_log

        -- 2. Finish the block: writes trie data files to object store.
        let finished_tables = source.live_index.finishBlock(block_index)
        let tries = finished_tables.collectTries()

        -- 3. Notify replicas that tries exist.
        let tries_added = TriesAddedMessage.created(tries: tries)
        tries_added appended to database.replica_log

        -- Register tries locally on the source.
        trie_cat/trie_catalog.addTries(tries, log_timestamp)

        -- Update source's table catalog.
        source.table_catalog.finishBlock(finished_tables)

        -- 4. Write block file to object store.
        let block = Block.created(
            block_index: block_index,
            latest_completed_tx: source.live_index.latest_completed_tx,
            latest_processed_msg_id: source.latest_processed_msg_id,
            replica_log_offset: boundary.msg_id
        )
        block persisted to ObjectStore
        source.block_catalog.refresh(block)

        -- 5. Notify replicas that the block is available.
        let block_uploaded = BlockUploadedMessage.created(
            block_index: block_index,
            latest_processed_msg_id: source.latest_processed_msg_id,
            storage_epoch: current_storage_epoch
        )
        block_uploaded appended to database.replica_log

        -- 6. Reset for next block.
        source.live_index.nextBlock()

        -- Wake up compaction.
        CompactorSignalled()
}

------------------------------------------------------------
-- Rules: Replica Log Processing
------------------------------------------------------------

-- The ReplicaLogProcessor tails the replica log.
-- It applies pre-resolved OutputTxMessages directly (no query engine needed).
-- On BlockBoundary, it buffers until BlockUploaded, then transitions.

rule ReplicaProcessesOutputTx {
    when: msg: OutputTxMessage appended to database.replica_log

    requires: msg.msg_id > replica.latest_processed_msg_id

    ensures:
        -- Import the pre-resolved table relations into the replica's live index.
        ApplyOutputTx(msg, replica.live_index)
        replica.latest_processed_msg_id = msg.msg_id
}

rule ReplicaProcessesTriesAdded {
    when: msg: TriesAddedMessage appended to database.replica_log

    requires: msg.msg_id > replica.latest_processed_msg_id
    requires: msg.storage_version == current_storage_version
    requires: msg.storage_epoch == current_storage_epoch

    ensures:
        trie_cat/trie_catalog.addTries(msg.tries, msg.log_timestamp)
        replica.latest_processed_msg_id = msg.msg_id
}

rule ReplicaBuffersAtBlockBoundary {
    -- When the replica sees a BlockBoundary, it stops processing OutputTxMessages
    -- and buffers until BlockUploaded arrives for that block.
    when: msg: BlockBoundaryMessage appended to database.replica_log

    requires: msg.msg_id > replica.latest_processed_msg_id

    let block_index = msg.block_index

    ensures:
        let (buffered, uploaded_msg) = consumeUntil BlockUploadedMessage from database.replica_log
            where uploaded_msg.block_index == block_index
              and uploaded_msg.storage_epoch == current_storage_epoch

        ReplicaTransitionsBlock(block_index, buffered)
}

rule ReplicaTransitionsBlock {
    when: ReplicaTransitionsBlock(block_index, buffered)

    ensures:
        -- Refresh catalogs from what the source wrote to the object store.
        replica.block_catalog.refresh(block_index)
        replica.table_catalog.refresh()
        trie_cat/trie_catalog.refresh()
        replica.live_index.nextBlock()

        -- Replay buffered messages into the new live index.
        for each buffered_msg in buffered:
            ReplicaProcessMessage(buffered_msg)
}

------------------------------------------------------------
-- Rules: Flush Timeout
------------------------------------------------------------

-- If transactions have been accumulating without a block flush,
-- the source sends itself a FlushBlock message.

rule FlushTimeoutFires {
    when: source.last_flush_check + config.flush_timeout <= now

    requires: database.mode == read_write
    requires: source.live_index.has_data
    requires: source.block_catalog.current_block_index unchanged since source.last_flush_check

    ensures:
        FlushBlockMessage.created(
            expected_block_idx: source.block_catalog.current_block_index
        ) appended to database.source_log
}

------------------------------------------------------------
-- Rules: Source Recovery
------------------------------------------------------------

-- The two-log problem: the source consumes from source log and writes to replica log.
-- A crash between consume and write creates inconsistency.
-- Recovery uses a three-phase Replay-then-Resume protocol.

rule SourceHydratesFromBlock {
    -- Phase 1: On partition assignment, hydrate state from the latest block.
    when: SourcePartitionAssigned(database)

    ensures:
        let block = source.block_catalog.latest_block

        -- Hydrate source's live index, catalogs from block (as today).
        source.hydrateFrom(block)

        -- Continue to phase 2.
        SourceCatchesUpFromReplicaLog(block)
}

rule SourceCatchesUpFromReplicaLog {
    -- Phase 2: Replay from replica log to rebuild in-memory state.
    -- The source acts as a replica during this phase.
    when: SourceCatchesUpFromReplicaLog(block)

    let resume_offset = block?.replica_log_offset ?? beginning

    ensures:
        -- Tail replica log from block's replica_log_offset to current end.
        let last_source_msg_id = block?.latest_processed_msg_id

        for each msg in database.replica_log from resume_offset:
            match msg:
                OutputTxMessage ->
                    ApplyOutputTx(msg, source.live_index)
                    last_source_msg_id = msg.source_msg_id
                TriesAddedMessage ->
                    trie_cat/trie_catalog.addTries(msg.tries, msg.log_timestamp)
                BlockUploadedMessage ->
                    -- Block transition during catch-up.
                    source.block_catalog.refresh(msg.block_index)
                    source.table_catalog.refresh()
                    source.live_index.nextBlock()
                BlockBoundaryMessage ->
                    -- Handled implicitly by subsequent BlockUploaded.
                    pass

        -- Continue to phase 3 with the resume point.
        SourceResumesFromSourceLog(last_source_msg_id)
}

rule SourceResumesFromSourceLog {
    -- Phase 3: Resume from source log with transactional producer.
    when: SourceResumesFromSourceLog(last_source_msg_id)

    ensures:
        -- Seek source log to last_source_msg_id + 1.
        -- Open transactional producer on replica log.
        -- Enter steady-state processing (SourceProcessesTx etc).
        source.latest_processed_msg_id = last_source_msg_id
        SourceEntersSteadyState()
}

------------------------------------------------------------
-- Rules: Query Serving
------------------------------------------------------------

rule ClientOpensSnapshot {
    when: ClientOpensSnapshot(client, database)

    ensures:
        -- Queries are served from the replica's live index,
        -- even on the leader node.
        Snapshot.created(
            as_of: replica.live_index.latest_completed_tx
        )
}

------------------------------------------------------------
-- Rules: Error Handling
------------------------------------------------------------

rule ProcessingErrorHaltsNode {
    -- Any unrecoverable error during log processing is fatal.
    -- The node is marked unhealthy; orchestration should restart it.
    when: ProcessingError(msg_id, error)

    ensures:
        -- All pending watchers are notified of the error.
        -- LogProcessor stops permanently.
        -- No partial state corruption: either a message is fully processed or not at all.
        NodeMarkedUnhealthy()
}

------------------------------------------------------------
-- Surfaces
------------------------------------------------------------

actor Client {
    identified_by: external session
}

surface TransactionSubmission {
    for caller: Client

    context db: Database

    provides:
        ClientSubmitsTx(caller, db, tx_ops, opts)
            when db.mode == read_write

    invariant: OrderedProcessing
        -- Transactions are processed in source-log order, not submission order.
}

surface QueryAccess {
    for caller: Client

    context db: Database

    provides:
        ClientOpensSnapshot(caller, db)

    invariant: SnapshotIsolation
        -- A snapshot sees a consistent point-in-time view.
        -- It includes all transactions up to the replica's latest_completed_tx.
}

------------------------------------------------------------
-- Deferred Specifications
------------------------------------------------------------

deferred ResolveTransaction        -- source-side tx resolution: put/delete/erase logic, SQL execution
deferred ApplyOutputTx             -- replica-side import of pre-resolved table relations into live index
deferred TxSourceConsumesOutputTx  -- tx-source reads resolved txs from replica log, not source txs

------------------------------------------------------------
-- Open Questions
------------------------------------------------------------

open_question "Source recovery phase 2: should catch-up be synchronous within onPartitionsAssigned? Risk of exceeding Kafka's max.poll.interval.ms for large replay windows."
open_question "Transactional producer design: AtomicProducer.Tx needs commitWithConsumerOffsets for Kafka's sendOffsetsToTransaction. InMemory/Local implementations: no-op (single process)."
